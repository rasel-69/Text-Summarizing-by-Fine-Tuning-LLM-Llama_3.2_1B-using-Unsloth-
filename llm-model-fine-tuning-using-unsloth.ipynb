{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-19T18:26:18.084433Z",
     "iopub.status.busy": "2025-10-19T18:26:18.084112Z",
     "iopub.status.idle": "2025-10-19T18:26:18.089871Z",
     "shell.execute_reply": "2025-10-19T18:26:18.089343Z",
     "shell.execute_reply.started": "2025-10-19T18:26:18.084410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-summary/news_summary_more.csv\n",
      "/kaggle/input/news-summary/news_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:27:16.645355Z",
     "iopub.status.busy": "2025-10-19T18:27:16.645092Z",
     "iopub.status.idle": "2025-10-19T18:27:16.649316Z",
     "shell.execute_reply": "2025-10-19T18:27:16.648542Z",
     "shell.execute_reply.started": "2025-10-19T18:27:16.645336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:28:53.752725Z",
     "iopub.status.busy": "2025-10-19T18:28:53.751942Z",
     "iopub.status.idle": "2025-10-19T18:28:53.900974Z",
     "shell.execute_reply": "2025-10-19T18:28:53.900231Z",
     "shell.execute_reply.started": "2025-10-19T18:28:53.752697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/news-summary/news_summary.csv',encoding='iso-8859-1')\n",
    "\n",
    "# -------- this data has a common encoding issue, it doesn't use utf-8 which is the default value ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASIC EAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:30:12.860076Z",
     "iopub.status.busy": "2025-10-19T18:30:12.859086Z",
     "iopub.status.idle": "2025-10-19T18:30:12.870374Z",
     "shell.execute_reply": "2025-10-19T18:30:12.869542Z",
     "shell.execute_reply.started": "2025-10-19T18:30:12.860004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>Mansha Mahajan</td>\n",
       "      <td>24 Feb 2017,Friday</td>\n",
       "      <td>Rasna seeking ?250 cr revenue from snack categ...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/rasna-eyes-...</td>\n",
       "      <td>Fruit juice concentrate maker Rasna is eyeing ...</td>\n",
       "      <td>Mumbai, Feb 23 (PTI) Fruit juice concentrate m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>Dishant Sharma</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Sachin attends Rajya Sabha after questions on ...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sachin-tend...</td>\n",
       "      <td>Former Indian cricketer Sachin Tendulkar atten...</td>\n",
       "      <td>Former cricketer Sachin Tendulkar was spotted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>Tanya Dhingra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Shouldn't rob their childhood: Aamir on kids r...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/secret...</td>\n",
       "      <td>Aamir Khan, while talking about reality shows ...</td>\n",
       "      <td>Aamir Khan, whose last film Dangal told the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>07 Dec 2016,Wednesday</td>\n",
       "      <td>Asha Bhosle gets ?53,000 power bill for unused...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/singer-asha...</td>\n",
       "      <td>The Maharashtra government has initiated an in...</td>\n",
       "      <td>Maharahstra Power Minister Chandrashekhar Bawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>More than half of India's languages may die in...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/indian-lang...</td>\n",
       "      <td>At least 400 languages or more than half langu...</td>\n",
       "      <td>More than half of the languages spoken by Indi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4514 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author                   date  \\\n",
       "0           Chhavi Tyagi   03 Aug 2017,Thursday   \n",
       "1            Daisy Mowke   03 Aug 2017,Thursday   \n",
       "2         Arshiya Chopra   03 Aug 2017,Thursday   \n",
       "3          Sumedha Sehra   03 Aug 2017,Thursday   \n",
       "4     Aarushi Maheshwari   03 Aug 2017,Thursday   \n",
       "...                  ...                    ...   \n",
       "4509      Mansha Mahajan     24 Feb 2017,Friday   \n",
       "4510      Dishant Sharma   03 Aug 2017,Thursday   \n",
       "4511       Tanya Dhingra   03 Aug 2017,Thursday   \n",
       "4512      Pragya Swastik  07 Dec 2016,Wednesday   \n",
       "4513        Chhavi Tyagi   03 Aug 2017,Thursday   \n",
       "\n",
       "                                              headlines  \\\n",
       "0     Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1     Malaika slams user who trolled her for 'divorc...   \n",
       "2     'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3     Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4     Hotel staff to get training to spot signs of s...   \n",
       "...                                                 ...   \n",
       "4509  Rasna seeking ?250 cr revenue from snack categ...   \n",
       "4510  Sachin attends Rajya Sabha after questions on ...   \n",
       "4511  Shouldn't rob their childhood: Aamir on kids r...   \n",
       "4512  Asha Bhosle gets ?53,000 power bill for unused...   \n",
       "4513  More than half of India's languages may die in...   \n",
       "\n",
       "                                              read_more  \\\n",
       "0     http://www.hindustantimes.com/india-news/raksh...   \n",
       "1     http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2     http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3     http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4     http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "...                                                 ...   \n",
       "4509  http://indiatoday.intoday.in/story/rasna-eyes-...   \n",
       "4510  http://indiatoday.intoday.in/story/sachin-tend...   \n",
       "4511  http://www.hindustantimes.com/bollywood/secret...   \n",
       "4512  http://indiatoday.intoday.in/story/singer-asha...   \n",
       "4513  http://indiatoday.intoday.in/story/indian-lang...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     The Administration of Union Territory Daman an...   \n",
       "1     Malaika Arora slammed an Instagram user who tr...   \n",
       "2     The Indira Gandhi Institute of Medical Science...   \n",
       "3     Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4     Hotels in Maharashtra will train their staff t...   \n",
       "...                                                 ...   \n",
       "4509  Fruit juice concentrate maker Rasna is eyeing ...   \n",
       "4510  Former Indian cricketer Sachin Tendulkar atten...   \n",
       "4511  Aamir Khan, while talking about reality shows ...   \n",
       "4512  The Maharashtra government has initiated an in...   \n",
       "4513  At least 400 languages or more than half langu...   \n",
       "\n",
       "                                                  ctext  \n",
       "0     The Daman and Diu administration on Wednesday ...  \n",
       "1     From her special numbers to TV?appearances, Bo...  \n",
       "2     The Indira Gandhi Institute of Medical Science...  \n",
       "3     Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4     Hotels in Mumbai and other Indian cities are t...  \n",
       "...                                                 ...  \n",
       "4509  Mumbai, Feb 23 (PTI) Fruit juice concentrate m...  \n",
       "4510  Former cricketer Sachin Tendulkar was spotted ...  \n",
       "4511  Aamir Khan, whose last film Dangal told the st...  \n",
       "4512  Maharahstra Power Minister Chandrashekhar Bawa...  \n",
       "4513  More than half of the languages spoken by Indi...  \n",
       "\n",
       "[4514 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:29:11.216652Z",
     "iopub.status.busy": "2025-10-19T18:29:11.216107Z",
     "iopub.status.idle": "2025-10-19T18:29:11.221265Z",
     "shell.execute_reply": "2025-10-19T18:29:11.220676Z",
     "shell.execute_reply.started": "2025-10-19T18:29:11.216627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:30:35.548069Z",
     "iopub.status.busy": "2025-10-19T18:30:35.547415Z",
     "iopub.status.idle": "2025-10-19T18:30:35.556544Z",
     "shell.execute_reply": "2025-10-19T18:30:35.555815Z",
     "shell.execute_reply.started": "2025-10-19T18:30:35.548032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         0\n",
       "date           0\n",
       "headlines      0\n",
       "read_more      0\n",
       "text           0\n",
       "ctext        118\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:31:41.007166Z",
     "iopub.status.busy": "2025-10-19T18:31:41.006504Z",
     "iopub.status.idle": "2025-10-19T18:31:46.213171Z",
     "shell.execute_reply": "2025-10-19T18:31:46.212425Z",
     "shell.execute_reply.started": "2025-10-19T18:31:41.007139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text preprocessing and cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:37:57.908609Z",
     "iopub.status.busy": "2025-10-19T18:37:57.907856Z",
     "iopub.status.idle": "2025-10-19T18:37:59.705962Z",
     "shell.execute_reply": "2025-10-19T18:37:59.705156Z",
     "shell.execute_reply.started": "2025-10-19T18:37:57.908585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import contractions # removes english's notation that makes word embedding more computationally expensive\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)  # ensuring input is string \n",
    "    text = text.lower()  # converting everyting lowercase\n",
    "    text = contractions.fix(text)  # expand contractions\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)  # remove brackets including text inside it\n",
    "    text = re.sub('\"','', text)          # remove all double quations\n",
    "    text = re.sub(r\"'s\\b\",\"\",text)     #Removes possessive “’s” at the end of words.\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)   #Keeps only alphabets — removes numbers, punctuation, emojis, etc.\n",
    "    text = re.sub('[m]{2,}', 'mm', text)   #Replaces multiple consecutive “m” letters with just “mm”.\n",
    "    text = re.sub('\\s+', ' ', text)   # removing multiple spaces\n",
    "    return text\n",
    "data=pd.DataFrame()\n",
    "data['ctext'] = df['ctext'].apply(clean_text)\n",
    "data['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:38:18.841524Z",
     "iopub.status.busy": "2025-10-19T18:38:18.841260Z",
     "iopub.status.idle": "2025-10-19T18:38:18.846664Z",
     "shell.execute_reply": "2025-10-19T18:38:18.846092Z",
     "shell.execute_reply.started": "2025-10-19T18:38:18.841506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the administration of union territory daman and diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of rakshabandhan on august the administration was forced to withdraw the decision within hours of issuing the circular after it received flak from employees and was slammed on social media '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:38:43.441139Z",
     "iopub.status.busy": "2025-10-19T18:38:43.440861Z",
     "iopub.status.idle": "2025-10-19T18:38:43.445963Z",
     "shell.execute_reply": "2025-10-19T18:38:43.445382Z",
     "shell.execute_reply.started": "2025-10-19T18:38:43.441118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0] # here in the ouput we can see tha changes before and after text preprocssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:40:18.182922Z",
     "iopub.status.busy": "2025-10-19T18:40:18.182640Z",
     "iopub.status.idle": "2025-10-19T18:40:18.277817Z",
     "shell.execute_reply": "2025-10-19T18:40:18.277124Z",
     "shell.execute_reply.started": "2025-10-19T18:40:18.182901Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "11686\n"
     ]
    }
   ],
   "source": [
    "max_text_words = max([len(list(text.split(\" \"))) for text in data['text']])\n",
    "max_ctext_words = max([len(list(ctexts.split(\" \"))) for ctexts in data['ctext']])\n",
    "\n",
    "\n",
    "print(max_text_words)\n",
    "print(max_ctext_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:43:42.703267Z",
     "iopub.status.busy": "2025-10-19T18:43:42.702537Z",
     "iopub.status.idle": "2025-10-19T18:45:41.747967Z",
     "shell.execute_reply": "2025-10-19T18:45:41.746791Z",
     "shell.execute_reply.started": "2025-10-19T18:43:42.703233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-x9_4on1r/unsloth_77b8a987b6d742bdb3a4f330d6fac319\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-x9_4on1r/unsloth_77b8a987b6d742bdb3a4f330d6fac319\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 98d82a769b6a4dbefb5638eb0c64e17c73363be1\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting unsloth_zoo>=2025.10.6 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading unsloth_zoo-2025.10.7-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
      "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.52.4)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
      "Collecting torchao!=0.14.0,>=0.13.0 (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading torchao-0.13.0-1-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.1)\n",
      "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.23.0,>=0.7.9 (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting mistral_common (from unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.0)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.12.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.6.15)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.11.7)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.24.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.0)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.20.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.25.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
      "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common->unsloth_zoo>=2025.10.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
      "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.10.7-py3-none-any.whl (267 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchao-0.13.0-1-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for unsloth: filename=unsloth-2025.10.6-py3-none-any.whl size=347096 sha256=2cb19a318863392eaa54e9b0bebe49659966543b67ebfcc1d66f2df045df84b0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nqolj434/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
      "Successfully built unsloth\n",
      "Installing collected packages: torchao, unsloth, shtab, pycountry, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, tokenizers, pydantic-extra-types, nvidia-cusolver-cu12, cut_cross_entropy, transformers, trl, mistral_common, unsloth_zoo, bitsandbytes\n",
      "  Attempting uninstall: torchao\n",
      "    Found existing installation: torchao 0.10.0\n",
      "    Uninstalling torchao-0.10.0:\n",
      "      Successfully uninstalled torchao-0.10.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.33.1\n",
      "    Uninstalling huggingface-hub-0.33.1:\n",
      "      Successfully uninstalled huggingface-hub-0.33.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.4\n",
      "    Uninstalling transformers-4.52.4:\n",
      "      Successfully uninstalled transformers-4.52.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.48.1 cut_cross_entropy-25.1.1 fsspec-2025.3.0 huggingface_hub-0.35.3 mistral_common-1.8.5 msgspec-0.19.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pycountry-24.6.1 pydantic-extra-types-2.10.6 shtab-1.7.2 tokenizers-0.22.1 torchao-0.13.0 transformers-4.56.2 trl-0.23.0 tyro-0.9.35 unsloth-2025.10.6 unsloth_zoo-2025.10.7\n",
      "Collecting xformers<0.0.27\n",
      "  Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting trl<0.9.0\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.48.1)\n",
      "Downloading xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xformers, trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.23.0\n",
      "    Uninstalling trl-0.23.0:\n",
      "      Successfully uninstalled trl-0.23.0\n",
      "Successfully installed trl-0.8.6 xformers-0.0.26.post1\n"
     ]
    }
   ],
   "source": [
    "# Install Unsloth\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:46:05.530041Z",
     "iopub.status.busy": "2025-10-19T18:46:05.529757Z",
     "iopub.status.idle": "2025-10-19T18:46:45.192078Z",
     "shell.execute_reply": "2025-10-19T18:46:45.191501Z",
     "shell.execute_reply.started": "2025-10-19T18:46:05.530014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Unsloth libraries\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:46:53.432548Z",
     "iopub.status.busy": "2025-10-19T18:46:53.431676Z",
     "iopub.status.idle": "2025-10-19T18:46:53.436369Z",
     "shell.execute_reply": "2025-10-19T18:46:53.435552Z",
     "shell.execute_reply.started": "2025-10-19T18:46:53.432516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Disable wandb completely\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:52:48.859253Z",
     "iopub.status.busy": "2025-10-19T18:52:48.858942Z",
     "iopub.status.idle": "2025-10-19T18:52:48.862830Z",
     "shell.execute_reply": "2025-10-19T18:52:48.862134Z",
     "shell.execute_reply.started": "2025-10-19T18:52:48.859226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048  # We auto support RoPE Scaling internally!\n",
    "dtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Pretraind Model with Unsloth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:52:52.948874Z",
     "iopub.status.busy": "2025-10-19T18:52:52.948637Z",
     "iopub.status.idle": "2025-10-19T18:53:03.502272Z",
     "shell.execute_reply": "2025-10-19T18:53:03.501562Z",
     "shell.execute_reply.started": "2025-10-19T18:52:52.948858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.6: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd7e4919af44e7ba0439f97a706b0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe62a30639ac4364aa494c9f64d7b6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daa3c6d33354251ac992961bf0635a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b50fadbeadf4dafb95d967589631d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1300a465e49c4d8dba4b1f373dcf8078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model - you can choose different models here\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(    #Loading pretrained model and its tokenizer.\n",
    "    model_name = \"unsloth/llama-3.2-1b-instruct-bnb-4bit\", # You can choose any model\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    \n",
    ")\n",
    "\n",
    "#converts text tokens (numerical IDs the model understands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrating QLoRA adaptors for PEFT (Parameter-Efficient Fine-Tuning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:58:00.518138Z",
     "iopub.status.busy": "2025-10-19T18:58:00.517506Z",
     "iopub.status.idle": "2025-10-19T18:58:06.465514Z",
     "shell.execute_reply": "2025-10-19T18:58:06.464705Z",
     "shell.execute_reply.started": "2025-10-19T18:58:00.518114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.10.6 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # LORa metrics Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],  #Only these layers are trainable; the rest of\n",
    "                                                                #the model remains frozen.\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset for training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T18:59:47.768370Z",
     "iopub.status.busy": "2025-10-19T18:59:47.767729Z",
     "iopub.status.idle": "2025-10-19T18:59:47.772577Z",
     "shell.execute_reply": "2025-10-19T18:59:47.771829Z",
     "shell.execute_reply.started": "2025-10-19T18:59:47.768345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def format_prompts(examples):\n",
    "    texts = examples[\"text\"]\n",
    "    summaries = examples[\"ctext\"]\n",
    "    formatted_texts = []\n",
    "    \n",
    "    for text, summary in zip(texts, summaries):\n",
    "        # Create instruction-following format\n",
    "        prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Summarize the following news article in a concise manner.\n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Response:\n",
    "{summary}\"\"\"\n",
    "        formatted_texts.append(prompt)\n",
    "    \n",
    "    return {\"text\": formatted_texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HuggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:01:13.690933Z",
     "iopub.status.busy": "2025-10-19T19:01:13.690655Z",
     "iopub.status.idle": "2025-10-19T19:01:13.794430Z",
     "shell.execute_reply": "2025-10-19T19:01:13.793605Z",
     "shell.execute_reply.started": "2025-10-19T19:01:13.690915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad56540cb91f4535bc0743c1a126238d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "dataset = dataset.map(format_prompts, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:02:13.587356Z",
     "iopub.status.busy": "2025-10-19T19:02:13.586779Z",
     "iopub.status.idle": "2025-10-19T19:02:13.592032Z",
     "shell.execute_reply": "2025-10-19T19:02:13.591363Z",
     "shell.execute_reply.started": "2025-10-19T19:02:13.587331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:03:35.673517Z",
     "iopub.status.busy": "2025-10-19T19:03:35.673264Z",
     "iopub.status.idle": "2025-10-19T19:03:35.677631Z",
     "shell.execute_reply": "2025-10-19T19:03:35.677085Z",
     "shell.execute_reply.started": "2025-10-19T19:03:35.673500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ctext', 'text'],\n",
       "    num_rows: 4514\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:02:45.802548Z",
     "iopub.status.busy": "2025-10-19T19:02:45.802306Z",
     "iopub.status.idle": "2025-10-19T19:02:45.812538Z",
     "shell.execute_reply": "2025-10-19T19:02:45.811847Z",
     "shell.execute_reply.started": "2025-10-19T19:02:45.802532Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4062\n",
      "Evaluation samples: 452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_data = train_dataset[\"train\"]\n",
    "eval_data = train_dataset[\"test\"]\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Evaluation samples: {len(eval_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:09:41.277532Z",
     "iopub.status.busy": "2025-10-19T19:09:41.277230Z",
     "iopub.status.idle": "2025-10-19T19:09:48.336285Z",
     "shell.execute_reply": "2025-10-19T19:09:48.335461Z",
     "shell.execute_reply.started": "2025-10-19T19:09:41.277510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289965ecd3d34582b80a49b87447d641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/4062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e26719962c426bb1110bb771a86cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "14.281 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# Training arguments\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = eval_data,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 2, # Set this for longer training!\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        save_steps = 100,\n",
    "        eval_strategy = \"steps\",\n",
    "        eval_steps = 100,\n",
    "        save_total_limit = 2,\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = \"eval_loss\",\n",
    "        greater_is_better = False,\n",
    "        report_to = None,  # Disable wandb and other reporting\n",
    "        disable_tqdm = False,  # Enable tqdm progress bars\n",
    "        dataloader_num_workers = 0,  # Set to 0 for better tqdm display\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:09:54.426635Z",
     "iopub.status.busy": "2025-10-19T19:09:54.425918Z",
     "iopub.status.idle": "2025-10-19T19:09:54.431531Z",
     "shell.execute_reply": "2025-10-19T19:09:54.430752Z",
     "shell.execute_reply.started": "2025-10-19T19:09:54.426605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: Tesla T4\n",
      "Memory allocated: 1.17 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU usage\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:10:24.335366Z",
     "iopub.status.busy": "2025-10-19T19:10:24.334687Z",
     "iopub.status.idle": "2025-10-19T19:10:24.338779Z",
     "shell.execute_reply": "2025-10-19T19:10:24.338216Z",
     "shell.execute_reply.started": "2025-10-19T19:10:24.335341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove any wandb callbacks that might still be there\n",
    "trainer.callback_handler.callbacks = [\n",
    "    cb for cb in trainer.callback_handler.callbacks \n",
    "    if 'wandb' not in str(type(cb)).lower()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T19:10:28.375566Z",
     "iopub.status.busy": "2025-10-19T19:10:28.375051Z",
     "iopub.status.idle": "2025-10-19T20:45:07.162297Z",
     "shell.execute_reply": "2025-10-19T20:45:07.161708Z",
     "shell.execute_reply.started": "2025-10-19T19:10:28.375544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4,062 | Num Epochs = 2 | Total steps = 508\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 11,272,192 of 1,247,086,592 (0.90% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='508' max='508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [508/508 1:34:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.876400</td>\n",
       "      <td>2.839515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.947500</td>\n",
       "      <td>2.798393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.891000</td>\n",
       "      <td>2.780049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.599100</td>\n",
       "      <td>2.772983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.599300</td>\n",
       "      <td>2.770150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    }
   ],
   "source": [
    "from unsloth import unsloth_train\n",
    "# unsloth_train fixes gradient_accumulation_steps\n",
    "# trainer_stats = trainer.train()\n",
    "trainer_stats = unsloth_train(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show final memory and time stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:45:45.736592Z",
     "iopub.status.busy": "2025-10-19T20:45:45.736297Z",
     "iopub.status.idle": "2025-10-19T20:45:45.742090Z",
     "shell.execute_reply": "2025-10-19T20:45:45.741559Z",
     "shell.execute_reply.started": "2025-10-19T20:45:45.736566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5676.49 seconds used for training.\n",
      "94.61 minutes used for training.\n",
      "Peak reserved memory = 14.303 GB.\n",
      "Peak reserved memory for training = 0.022 GB.\n",
      "Peak reserved memory % of max memory = 97.029 %.\n",
      "Peak reserved memory for training % of max memory = 0.149 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ============== INFERENCE AND TESTING =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:46:19.067635Z",
     "iopub.status.busy": "2025-10-19T20:46:19.067347Z",
     "iopub.status.idle": "2025-10-19T20:46:19.080563Z",
     "shell.execute_reply": "2025-10-19T20:46:19.079980Z",
     "shell.execute_reply.started": "2025-10-19T20:46:19.067614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Enable native 2x faster inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Test the model\n",
    "def generate_summary(text, max_length=150):\n",
    "    prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Summarize the following news article in a concise manner.\n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=max_length, \n",
    "        use_cache=True,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract only the response part\n",
    "    response = response.split(\"### Response:\")[1].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:46:30.277234Z",
     "iopub.status.busy": "2025-10-19T20:46:30.276940Z",
     "iopub.status.idle": "2025-10-19T20:46:35.831491Z",
     "shell.execute_reply": "2025-10-19T20:46:35.830806Z",
     "shell.execute_reply.started": "2025-10-19T20:46:30.277214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "the administration of union territory daman and diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of rakshabandhan on august the administration was forced to withdraw the decision within hours of issuing the circular after it received flak from employees and was slammed on social media ...\n",
      "\n",
      "Original Summary:\n",
      "the daman and diu administration on wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media the union territory s administration was forced to retreat within hours of issuing the circular that made it compulsory for its staff to celebrate rakshabandhan at workplace it has been decided to celebrate the festival of rakshabandhan on august in this connection all offices departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues the order issued on august by gurpreet singh deputy secretary had said to ensure that no one skipped office an attendance report was to be sent to the government the next evening the two notifications one mandating the celebration of rakshabandhan and the other withdrawing the mandate were issued by the daman and diu administration a day apart the circular was withdrawn through a one line order issued late in the evening by the ut s department of personnel and administrative reforms the circular is ridiculous there are sensitivities involved how can the government dictate who i should tie rakhi to we should maintain the professionalism of a workplace an official told hindustan times earlier in the day she refused to be identified the notice was issued on daman and diu administrator and former gujarat home minister praful kodabhai patel s direction sources said rakshabandhan a celebration of the bond between brothers and sisters is one of several hindu festivities and rituals that are no longer confined of private family affairs but have become tools to push politic al ideologies in the year bjp stormed to power at the centre rashtriya swayamsevak sangh chief mohan bhagwat said the festival had national significance and should be celebrated widely to protect hindu culture and live by the values enshrined in it the rss is the ideological parent of the ruling bjp last year women ministers in the modi government went to the border areas to celebrate the festival with soldiers a year before all cabinet ministers were asked to go to their constituencies for the festival \n",
      "\n",
      "Generated Summary:\n",
      "daman and diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of rakshabandhan on august the administration was forced to withdraw the decision within hours of issuing the circular after it received flak from employees and was slammed on social media daman and diu was also slapped with a notice for misuse of government property and misappropriation of funds for the occasion the administration of union territory daman and diu had issued a circular on august that made it compulsory for women to tie rakhis to their male colleagues on the occasion of rakshabandhan a month before the festival of rakshabandhan which is celebrated to mark the union government s decision on august\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample from the dataset\n",
    "test_idx = 0\n",
    "original_text = data.iloc[test_idx]['text']\n",
    "original_summary = data.iloc[test_idx]['ctext']\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(original_text[:500] + \"...\")\n",
    "print(\"\\nOriginal Summary:\")\n",
    "print(original_summary)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "generated_summary = generate_summary(original_text)\n",
    "print(generated_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ============== SAVE MODEL =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:48:48.934957Z",
     "iopub.status.busy": "2025-10-19T20:48:48.934658Z",
     "iopub.status.idle": "2025-10-19T20:48:49.470175Z",
     "shell.execute_reply": "2025-10-19T20:48:49.469410Z",
     "shell.execute_reply.started": "2025-10-19T20:48:48.934936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"news_summarizer_Llama3.2-1B\") # Local saving\n",
    "tokenizer.save_pretrained(\"news_summarizer_Llama_tokenizer\")\n",
    "\n",
    "# Optional: Save to HuggingFace Hub (uncomment and add your token)\n",
    "# model.push_to_hub(\"your_username/news_summarizer\", token=\"your_hf_token\")\n",
    "# tokenizer.push_to_hub(\"your_username/news_summarizer\", token=\"your_hf_token\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:58:47.300057Z",
     "iopub.status.busy": "2025-10-19T20:58:47.299743Z",
     "iopub.status.idle": "2025-10-19T20:58:47.305095Z",
     "shell.execute_reply": "2025-10-19T20:58:47.304241Z",
     "shell.execute_reply.started": "2025-10-19T20:58:47.300032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (703456169.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_36/703456169.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.push_to_hub(\"Rasel2091/news_summarizer_Llama-3.2_1B\", token=\"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\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save to HuggingFace Hub (uncomment and add your token)\n",
    " model.push_to_hub(\"Rasel2091/news_summarizer_Llama-3.2_1B\", token=\"HF write toke heren \")\n",
    " tokenizer.push_to_hub(\"your_username/news_summarizer_Llama-3.2_1B_tokenizer\", token=\"HF write toke heren \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T21:00:02.614842Z",
     "iopub.status.busy": "2025-10-19T21:00:02.614563Z",
     "iopub.status.idle": "2025-10-19T21:00:09.533194Z",
     "shell.execute_reply": "2025-10-19T21:00:09.532433Z",
     "shell.execute_reply.started": "2025-10-19T21:00:02.614819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541042a63476418f910e26e010233ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/598 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef95a06741246a89e4b65124545e629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee261f1153641dbb91ebc9a0caf6c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/Rasel2091/news_summarizer_Llama-3.2_1B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1761b32b971b4c4fbdbe941e6fbbe46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64310ec5c6264f1fb64e0f0d96cde84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Save to HuggingFace Hub (uncomment and add your token)\n",
    "model.push_to_hub(\n",
    "    \"model/news_summarizer_Llama-3.2_1B\", \n",
    "    token=\"HF write toke heren \"\n",
    ")\n",
    "\n",
    "tokenizer.push_to_hub(\n",
    "    \"model/news_summarizer_Llama-3.2_1B_tokenizer\", \n",
    "    token=\"HF write toke heren \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:50:55.187746Z",
     "iopub.status.busy": "2025-10-19T20:50:55.186980Z",
     "iopub.status.idle": "2025-10-19T20:50:57.377483Z",
     "shell.execute_reply": "2025-10-19T20:50:57.376843Z",
     "shell.execute_reply.started": "2025-10-19T20:50:55.187721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder zipped successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to your folder in Kaggle kernel\n",
    "source_folder = \"/kaggle/working/news_summarizer_Llama3.2-1B\"\n",
    "\n",
    "# Create a zip file\n",
    "shutil.make_archive(\"/kaggle/working/news_summarizer_Llama3.2-1B\", 'zip', source_folder)\n",
    "\n",
    "print(\"Folder zipped successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T20:52:14.227114Z",
     "iopub.status.busy": "2025-10-19T20:52:14.226859Z",
     "iopub.status.idle": "2025-10-19T20:52:14.649495Z",
     "shell.execute_reply": "2025-10-19T20:52:14.648852Z",
     "shell.execute_reply.started": "2025-10-19T20:52:14.227096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder zipped successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to your folder in Kaggle kernel\n",
    "source_folder = \"/kaggle/working/news_summarizer_Llama_tokenizer\"\n",
    "\n",
    "# Create a zip file\n",
    "shutil.make_archive(\"/kaggle/working/news_summarizer_Llama_tokenizer\", 'zip', source_folder)\n",
    "\n",
    "print(\"Folder zipped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1895,
     "sourceId": 791838,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
